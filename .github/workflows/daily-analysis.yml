name: Daily Institutional Analysis (Ultra-Fast)

on:
  push:
    branches: [ main ]
  schedule:
    - cron: '30 0 * * *' # 6:00 AM IST (00:30 UTC)
  workflow_dispatch:

# Optimize concurrency
concurrency:
  group: market-data-generation
  cancel-in-progress: true

jobs:
  # Job 1: Fetch India Stocks (parallelized in batches)
  fetch-india-stocks:
    runs-on: ubuntu-latest
    strategy:
      max-parallel: 5
      matrix:
       batch: [1, 2, 3, 4, 5]  # Split 50 stocks into 5 batches of 10
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v3

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.9'
        cache: 'pip'

    - name: Cache pip dependencies
      uses: actions/cache@v3
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-pip-${{ hashFiles('scripts/requirements.txt') }}
        restore-keys: |
          ${{ runner.os }}-pip-

    - name: Install dependencies
      run: |
        pip install -r scripts/requirements.txt

    - name: Fetch India Stocks Batch ${{ matrix.batch }}
      working-directory: scripts
      run: |
        python -c "
        import sys
        sys.path.insert(0, '.')
        from fetchers.stocks_async import fetch_stock_data, NIFTY_50_TICKERS
        import json
        batch_size = 10
        batch_num = ${{ matrix.batch }} - 1
        start = batch_num * batch_size
        end = start + batch_size
        tickers = NIFTY_50_TICKERS[start:end]
        data = fetch_stock_data(tickers)
        with open('../india_batch_${{ matrix.batch }}.json', 'w') as f:
            json.dump(data, f)
        "

    - name: Upload India Batch ${{ matrix.batch }}
      uses: actions/upload-artifact@v4
      with:
        name: india-batch-${{ matrix.batch }}
        path: india_batch_${{ matrix.batch }}.json
        retention-days: 1
  
  # Job 2: Fetch US Stocks & Crypto (in parallel)
  fetch-us-and-crypto:
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v3

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.9'
        cache: 'pip'

    - name: Cache pip dependencies
      uses: actions/cache@v3
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-pip-${{ hashFiles('scripts/requirements.txt') }}
        restore-keys: |
          ${{ runner.os }}-pip-

    - name: Install dependencies
      run: |
        pip install -r scripts/requirements.txt

    - name: Fetch US Stocks
      working-directory: scripts
      run: |
        python -c "
        import sys
        sys.path.insert(0, '.')
        from fetchers.stocks_async import fetch_stock_data, US_TICKERS
        import json
        data = fetch_stock_data(US_TICKERS)
        with open('../us_stocks.json', 'w') as f:
            json.dump(data, f)
        "

    - name: Fetch Crypto Data
      working-directory: scripts
      run: |
        python -c "
        import sys
        sys.path.insert(0, '.')
        from fetchers.crypto import fetch_crypto_data
        import json
        data = fetch_crypto_data(20)
        with open('../crypto_data.json', 'w') as f:
            json.dump(data, f)
        "

    - name: Upload US & Crypto Data
      uses: actions/upload-artifact@v4
      with:
        name: us-and-crypto
        path: |
          us_stocks.json
          crypto_data.json
        retention-days: 1

  # Job 3: Fetch News (parallel feed parsing handled internally)
  fetch-news:
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v3

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.9'
        cache: 'pip'

    - name: Cache pip dependencies
      uses: actions/cache@v3
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-pip-${{ hashFiles('scripts/requirements.txt') }}
        restore-keys: |
          ${{ runner.os }}-pip-

    - name: Install dependencies
      run: |
        pip install -r scripts/requirements.txt

    - name: Fetch News
      working-directory: scripts
      run: |
        python -c "
        import sys
        sys.path.insert(0, '.')
        from fetchers.news import fetch_news
        import json
        data = fetch_news(50)
        with open('../news_data.json', 'w') as f:
            json.dump(data, f)
        "

    - name: Upload News Data
      uses: actions/upload-artifact@v4
      with:
        name: news-data
        path: news_data.json
        retention-days: 1

  # Job 4: Combine, Analyze & Generate Report
  combine-and-analyze:
    runs-on: ubuntu-latest
    needs: [fetch-india-stocks, fetch-us-and-crypto, fetch-news]
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v3

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.9'
        cache: 'pip'

    - name: Install dependencies
      run: |
        pip install -r scripts/requirements.txt

    # Download all artifacts
    - name: Download India Batch 1
      uses: actions/download-artifact@v4
      with:
        name: india-batch-1
        path: ./data

    - name: Download India Batch 2
      uses: actions/download-artifact@v4
      with:
        name: india-batch-2
        path: ./data

    - name: Download India Batch 3
      uses: actions/download-artifact@v4
      with:
        name: india-batch-3
        path: ./data

    - name: Download India Batch 4
      uses: actions/download-artifact@v4
      with:
        name: india-batch-4
        path: ./data

    - name: Download India Batch 5
      uses: actions/download-artifact@v4
      with:
        name: india-batch-5
        path: ./data

    - name: Download US & Crypto
      uses: actions/download-artifact@v4
      with:
        name: us-and-crypto
        path: ./data

    - name: Download News
      uses: actions/download-artifact@v4
      with:
        name: news-data
        path: ./data

    - name: Combine & Analyze Data
      env:
        EMAIL_USER: ${{ secrets.EMAIL_USER }}
        GMAIL_APP_PASSWORD: ${{ secrets.GMAIL_APP_PASSWORD }}
      run: |
        cd scripts
        python main_optimized.py

    - name: Generate & Send Email Report
      env:
        EMAIL_USER: ${{ secrets.EMAIL_USER }}
        GMAIL_APP_PASSWORD: ${{ secrets.GMAIL_APP_PASSWORD }}
      continue-on-error: true
      run: |
        cd scripts
        python -c "
        import json
        import sys
        import os
        sys.path.insert(0, '.')
        
        try:
            from analysis.report import generate_html_report
            from send_email import send_email
            
            with open('../app/public/latest_data.json', 'r') as f:
                app_data = json.load(f)
            
            html = generate_html_report(app_data)
            send_email(html)
            print('Email report sent successfully')
        except ImportError as e:
            print(f'Email sending skipped (modules not available): {e}')
        except Exception as e:
            print(f'Email sending failed: {e}')
        "

    - name: Set up Node.js
      uses: actions/setup-node@v4
      with:
        node-version: '20'
        cache: 'npm'
        cache-dependency-path: app/package-lock.json
    
    - name: Build Web App
      working-directory: ./app
      run: |
        npm ci
        npm run build
    
    - name: Set up Java 17
      uses: actions/setup-java@v4
      with:
        distribution: 'temurin'
        java-version: '17'
    
    - name: Setup Android SDK
      uses: android-actions/setup-android@v3
    
    - name: Build Android APK (Debug)
      working-directory: ./app
      run: |
        npx cap sync android
        cd android
        chmod +x ./gradlew
        ./gradlew assembleDebug --no-daemon --stacktrace
    
    - name: Upload Final Artifacts
      uses: actions/upload-artifact@v4
      with:
        name: daily-report-with-apk
        path: |
          app/public/latest_data.json
          scripts/templates/email_report.html
          app/android/app/build/outputs/apk/debug/app-debug.apk
        retention-days: 30
